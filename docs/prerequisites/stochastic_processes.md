# Stochastic Process

## Markov Processes
### Markov Chains
- Definition and properties
- Transition matrices and state classification (recurrent, transient, absorbing states)
- Stationary distributions and convergence properties

### Markov Decision Processes (MDPs)
- Definition and components (states, actions, rewards, transitions)
- Discounted and undiscounted rewards
- Bellman equations for value functions and policy evaluation
- Policy iteration and value iteration algorithms

---

## Martingales and Random Walks
### Martingales
- Definition and properties
- Stopping times and optional stopping theorem
- Applications in RL (e.g., convergence of algorithms)

### Random Walks
- Simple and biased random walks
- Connection to exploration in RL (e.g., epsilon-greedy strategies)
- Applications in stochastic environments

---

## Stochastic Approximation
### Robbins-Monro Algorithm
- Basic idea and convergence properties

### Applications in RL
- Temporal Difference (TD) learning and Q-learning
- Stochastic gradient descent in policy optimization



